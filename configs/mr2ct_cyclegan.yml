desc: "mr2ct cyclegan"

random_seed: 42
spatial_dim: 3
in_channel: 1   # in_channel is the same as the out_channel in cyclegan


# =======================
# === model architecture ==
# =======================
# generators
filters: [64, 96, 128, 192, 256, 384, 512, 768, 1024]  # filters reference from Optimized U-Net for Brain Tumor Segmentation <https://arxiv.org/pdf/2110.03352.pdf>
kernel_size: 
  - [3, 3, 3]
  - [3, 3, 3]
  - [3, 3, 3]
  - [3, 3, 3]
  - [3, 3, 3]
  - [3, 3, 3]
strides:
  - [1, 1, 1]
  - [2, 2, 1]
  - [2, 2, 1]
  - [2, 2, 2]
  - [2, 2, 2]
  - [2, 2, 2]

# discriminators
n_layers: 3
ndf: 64
norm_type: "instance"  # batch, instance

# =======================
# === Optimizers ========
# =======================

# optimizer, generators
generator:
  base_lr: 0.0002    # will be scaled by the number of GPUs, currently ban
  betas: [0.5, 0.999]
  weight_decay: 0.
  # lr_scheduler:
  warmup_epochs: 10

# optimizer, discriminators
discriminator:
  base_lr: 0.0002    # will be scaled by the number of GPUs, currently ban
  betas: [0.5, 0.999]
  weight_decay: 0.
  # lr_scheduler:
  warmup_epochs: 10

# =======================
# === Datasets ========
# =======================
# the data architecture should be like this:
# data_root_dir
# ├── pipeline_niigz_betneck
# │   ├── mr
# │   │   ├── 0001.nii.gz
# │   │   ├── 0002.nii.gz
# │   │   └── ...
# │   └── ct
# │       ├── 0001.nii.gz
# │       ├── 0002.nii.gz
# │       └── ...
# └── resampled_pipeline_niigz_betneck_brainsegs
#     └── mr
#         ├── 0001_brainseg.nii.gz
#         ├── 0002_brainseg.nii.gz
#         └── ...
file_suffix: ".nii.gz"
data_root_dir: "data"
image_subfolder_name: "pipeline_niigz_betneck"          # contains the mr and ct subfolders
mr_brainmask_subfolder_name: "resampled_pipeline_niigz_betneck_brainsegs/mr"  # contains the brain mask for mr
data_json_path: "data/mr2ct_cyclegan.json"    # if no json found in this path, it will be created in training
mr_crop_img_size: [448, 448, 56]
ct_crop_img_size: [448, 448, 56]
mr_final_img_size: [160, 160, 24]   # [384, 416, 56]
ct_final_img_size: [160, 160, 16]   # [384, 416, 56]
batch_size: 1
workers: 4

# transforms
mr_boder_pad: 10  # for considering the z-axis padding if using brain mask to crop the image


# =======================
# === Training ========
# =======================
total_epochs: 800
gan_mode: lsgan   # lsgan | wgangp | vanilla
cyclegan_image_pool_size: 50
lambda_cyc: 10.0
lambda_id: 1.0
lambda_gan: 1.0
use_tanh: True
save_checkpoint_freq: 20